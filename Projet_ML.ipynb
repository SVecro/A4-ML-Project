{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WixQFyx5s-sx"
   },
   "source": [
    "# Machine Learning Poject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\remig\\anaconda3\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qzKB6zCdt_Qm"
   },
   "source": [
    "## Project Overview\n",
    "\n",
    "This project presents an end-to-end workflow on a real-world dataset—from exploration to predictive modeling.\n",
    "\n",
    "**Task**\n",
    "\n",
    "We aim to predict the logarithm of an Airbnb listing’s price using its available features provided in a CSV file.\n",
    "\n",
    "**Workflow**\n",
    "\n",
    "\n",
    "\n",
    "*   Explore & understand the dataset.\n",
    "*   Clean & preprocess the data to make it analysis-ready.\n",
    "*   Engineer features that are informative for prediction.\n",
    "*   Build and evaluate predictive models.\n",
    "\n",
    "**Methodology**\n",
    "\n",
    "We will follow a rigorous process, explaining why each step is necessary, how it is implemented, and what conclusions we draw at each stage.\n",
    "\n",
    "**Objective**\n",
    "\n",
    "Beyond chasing raw performance, our primary goal is to deliver a critical, well-structured analysis of the approach and its results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v4DA4q5_y8Jd"
   },
   "source": [
    "## Topic choice\n",
    "\n",
    "We decide to choose a subject related to our major and our track respectively Industry&Robotic and Aerospace&Defense. For us a topic closely related to the real working world needs. Moreover, because we already works on data files in csv format last year for the data analysis project, we decide to choose an image based dataset to improve our skills and understanding of machine learning.\n",
    "\n",
    "After lots of ressearch to find good dataset that contained enough images with good quality to be processed with and related to an interested topic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Pqqi9CM3tb8"
   },
   "source": [
    "# Data Exploration\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset loading and imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans cette partie notre but est de regarder l'etat de santé du data set, son architectue, le nombre d'images, de label, leur coeherence ect. Ce sont des verification en amont de l'exploration des données car il est important de regarder l'etat du dataset avant de commencer de quelconques manipulation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Akt2QORcugK1"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'kagglehub'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# CORE IMPORTS\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mkagglehub\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mglob\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'kagglehub'"
     ]
    }
   ],
   "source": [
    "# CORE IMPORTS\n",
    "import os\n",
    "import kagglehub\n",
    "import glob\n",
    "import random\n",
    "\n",
    "from PIL import Image\n",
    "from collections import Counter\n",
    "\n",
    "# NUMERICS AND DATA HANDLING\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# IMAGE PROCESSING\n",
    "import cv2\n",
    "\n",
    "# VISUALIZATION\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4iBToyGMVQqd"
   },
   "source": [
    "Dataset Loading\n",
    "\n",
    "In this step, we search froù the dataset directory to find all image file paths\n",
    "and infer their class labels from the parent folder names. This information\n",
    "is then organized into a Pandas dataframe which will be easyier for analysis and manipulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KDm-zeVWVizA",
    "outputId": "88af3680-08ab-403b-b652-002d002a67c9"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'kagglehub' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Download latest version\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m path \u001b[38;5;241m=\u001b[39m kagglehub\u001b[38;5;241m.\u001b[39mdataset_download(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrhammell/planesnet\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPath to dataset files:\u001b[39m\u001b[38;5;124m\"\u001b[39m, path)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'kagglehub' is not defined"
     ]
    }
   ],
   "source": [
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"rhammell/planesnet\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I_Fne2CVT3Zb"
   },
   "source": [
    "Maintenant que nous avons charger notre jeu de données nous allons explorer l'arboresscence de notre jeu de données afin de confirmer sont organisation ce qui nous permettra de pouvoir l'utiliser correctement par la suite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LgCfzeKdl08T",
    "outputId": "0e1dc566-a291-4f3e-9a65-cf3e4f829d47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\raphp\\.cache\\kagglehub\\datasets\\rhammell\\planesnet\\versions\\4\n",
      "C:\\Users\\raphp\\.cache\\kagglehub\\datasets\\rhammell\\planesnet\\versions\\4\\planesnet\n",
      "C:\\Users\\raphp\\.cache\\kagglehub\\datasets\\rhammell\\planesnet\\versions\\4\\planesnet\\planesnet\n",
      "C:\\Users\\raphp\\.cache\\kagglehub\\datasets\\rhammell\\planesnet\\versions\\4\\scenes\n",
      "C:\\Users\\raphp\\.cache\\kagglehub\\datasets\\rhammell\\planesnet\\versions\\4\\scenes\\scenes\n"
     ]
    }
   ],
   "source": [
    "for root, dirs, files in os.walk(path):\n",
    "    print(root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B_8yYq3PUi6b"
   },
   "source": [
    "On voit donc ici que notre dossier du dataset est consituer de deux fichier (planesnet,scenes) tous deux constituer d'un sous dossiers idu meme nom. Afin de simplifier nos chemins allons créer une variable prenant le chemin du dossier des image.\n",
    "\n",
    "le dossier scene est different et sera utilisé pour la seconde partie du rojet concernant le deep learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "DEEOaQCtU1rm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train images dir : C:\\Users\\raphp\\.cache\\kagglehub\\datasets\\rhammell\\planesnet\\versions\\4\\planesnet\\planesnet\n"
     ]
    }
   ],
   "source": [
    "dataset_images = os.path.join(path, \"planesnet\\planesnet\")\n",
    "\n",
    "print(\"\\nTrain images dir :\", dataset_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WQsJxzKmWsUe"
   },
   "source": [
    "En premier lieu nous allons verifier si le nombre de labels et d'images est bien le meme pour chaque dossiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GLc_fluHVl6J",
    "outputId": "74f22015-415c-457b-831b-05da00b1467e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre d’images dans le dataset: 32000 \n"
     ]
    }
   ],
   "source": [
    "images_count = len(os.listdir(dataset_images))\n",
    "\n",
    "print(f\"Nombre d’images dans le dataset: {images_count} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "--SKTUhKmn0n"
   },
   "source": [
    "On a bien 32k d'image dans notre dataset mais cela est tres flou, nous allons devoir regarder en detail combien nous avons dimage dans nos deux differentes classe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nom de fichierdans le data set :\n",
      "- 0__20140723_181317_0905__-122.073653222_37.7090043618.png\n",
      "- 0__20140723_181317_0905__-122.083122783_37.7221653245.png\n",
      "- 0__20140723_181317_0905__-122.105473207_37.6723685004.png\n",
      "- 0__20140723_181317_0905__-122.1075857442429_37.643668625142496.png\n",
      "- 0__20140723_181317_0905__-122.14328662_37.697282118.png\n"
     ]
    }
   ],
   "source": [
    "# 1.1 – Inspection des noms de fichiers \n",
    "\n",
    "# Liste les 5 premiers fichiers du dataset\n",
    "sample_images = sorted(os.listdir(dataset_images))[:5]\n",
    "print(\"Nom de fichierdans le data set :\")\n",
    "for name in sample_images:\n",
    "    print(\"-\", name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
